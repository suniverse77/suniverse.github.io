---
layout: single
title: "[ë…¼ë¬¸ë¦¬ë·°] DreamVideo: Composing Your Dream Videos with Customized Subject and Motion"
last_modified_at: 2025-06-15
categories: ["ë…¼ë¬¸ë¦¬ë·°"]
tags: ["Video Generation"]
excerpt: "CVPR 2024"
use_math: true
toc: true
toc_sticky: true
---

**CVPR 2024** 
[[Paper]](https://arxiv.org/abs/2312.04433)
[[GitHub]](https://github.com/ali-vilab/VGen)

<details>
<summary><font color='#FF8C00'>ğŸ“ Summary</font></summary>
<div markdown="1">
<br>
ëª¨ë¸ ìµœì í™”ì˜ ë³µì¡ë„ë¥¼ ì¤„ì´ê³  ì»¤ìŠ¤í„°ë§ˆì´ì§•ì˜ ìœ ì—°ì„±ì„ ë†’ì´ê¸° ìœ„í•´ subject í•™ìŠµê³¼ motion í•™ìŠµì„ ë¶„ë¦¬í•˜ì˜€ë‹¤.
- 

</div>
</details>

## Introduction

**ê¸°ì¡´ ì—°êµ¬ë“¤ì˜ í•œê³„ì **

- ê³µê°„ì  contentì™€ ì‹œê°„ì  ì›€ì§ì„ì„ ë™ì‹œì— ì»¤ìŠ¤í„°ë§ˆì´ì§•í•˜ëŠ” ê²ƒì€ ì–´ë µë‹¤.
- ê¸°ì¡´ì˜ Dreamix, Tune-A-Videoì™€ ê°™ì€ ì—°êµ¬ì—ì„œëŠ” subjectì˜ ì •ì²´ì„± ë˜ëŠ” target motionë§Œ ìµœì í™”í•˜ë„ë¡ ì§‘ì¤‘í•˜ì˜€ë‹¤.
- [AnimateDiff](https://suniverse77.github.io/ë…¼ë¬¸ë¦¬ë·°/AnimateDiff/)ì—ì„œëŠ” personalized T2I ëª¨ë¸ì— temporal ëª¨ë“ˆì„ ë§ë¶™ì—¬ í•™ìŠµì‹œí‚¤ì§€ë§Œ, ìƒì„±ëœ ë¹„ë””ì˜¤ì˜ motionì´ ë‹¨ì¡°ë¡­ë‹¤.

**ì œì•ˆí•˜ëŠ” ë°©ë²•**

ì†Œìˆ˜ì˜ ì´ë¯¸ì§€ì™€ ë¹„ë””ì˜¤ë§Œìœ¼ë¡œë„ ì‚¬ìš©ìê°€ ì§€ì •í•œ subjectì™€ ì›í•˜ëŠ” motionì„ ìƒì„±í•  ìˆ˜ ìˆëŠ” DreamVideoë¥¼ ì œì•ˆí•œë‹¤.

- ëª¨ë¸ ìµœì í™”ì˜ ë³µì¡ë„ë¥¼ ì¤„ì´ê³  ì»¤ìŠ¤í„°ë§ˆì´ì§•ì˜ ìœ ì—°ì„±ì„ ë†’ì´ê¸° ìœ„í•´ subject í•™ìŠµê³¼ motion í•™ìŠµì„ ë¶„ë¦¬í•˜ì˜€ë‹¤.

## Methods

<center><img src='{{"/assets/images/ë…¼ë¬¸ë¦¬ë·°/DreamVideo-1.png" | relative_url}}' width="100%"></center>

### 1. DreamVideo

Subject í•™ìŠµê³¼ motion í•™ìŠµì„ ë¶„ë¦¬í•˜ì—¬, ë‘ ê°œì˜ ì–´ëŒ‘í„°ë¥¼ í†µí•´ ë§ì¶¤í˜• ë¹„ë””ì˜¤ ìƒì„± taskë¥¼ ìˆ˜í–‰í•œë‹¤.

ì‚¬ìš©ìëŠ” ì´ ë‘ ì–´ëŒ‘í„°ë¥¼ ê°„ë‹¨íˆ ê²°í•©í•¨ìœ¼ë¡œì¨ ì›í•˜ëŠ” ë¹„ë””ì˜¤ë¥¼ ìƒì„±í•  ìˆ˜ ìˆë‹¤.

#### Subject Learning

#### Motion Learning

### 2. Model Analysis, Training and Inference

Reference ì´ë¯¸ì§€ì˜ ì–¼êµ´, ì‹ ì²´ íŠ¹ì§•, ë°°ê²½ ìš”ì†Œ ê°™ì€ ì„¸ë°€í•œ ì •ë³´ë¥¼ ë³´ì¡´í•˜ê¸° ìœ„í•´ ì„¤ê³„í•˜ì˜€ë‹¤.

êµ¬ì²´ì ìœ¼ë¡œ, Appearance EncoderëŠ” base UNet $\mathcal{F}_a(\theta^a)$ì˜ êµ¬ì¡°ë¥¼ ë³µì œí•˜ì—¬ ì‚¬ìš©í•˜ì˜€ë‹¤. (trainable copy)

$$
\mathbf{y}_a=\mathcal{F}_a(\mathbf{z}_t\mid I_{\text{ref}},\mathbf{t},\theta^a)
$$

ì¸ì½”ë”© ê³¼ì •ì€ ìœ„ì™€ ê°™ì´ í‘œí˜„ë˜ë©°, $\mathbf{y}_a$ëŠ” UNetì˜ middle blockê³¼ upsampling blockì—ì„œì˜ attention hidden stateë¥¼ ì˜ë¯¸í•œë‹¤.

ë‹¨ìˆœíˆ ì¡°ê±´ì„ residual ë°©ì‹ìœ¼ë¡œ ë”í•˜ëŠ” ControlNetê³¼ ë‹¬ë¦¬, ì¡°ê±´ featureë¥¼ UNetì˜ spatial self-attention layerì— ì£¼ì…í•œë‹¤.

$$
\text{Attention}(Q,K,V,\mathbf{y}_a)=\text{Softmax}(\frac{QK'^\top}{\sqrt{d}})V'
$$

$$
Q=W^Q\mathbf{z}_t,~K'=W^K[\mathbf{z}_t,\mathbf{y}_a],~V'=W^V[\mathbf{z}_t,\mathbf{y}_a]
$$

Keyì™€ Valueë¥¼ ìƒì„±í•  ë•Œ, $\mathbf{y}_a$ì™€ ì›ë˜ UNetì˜ self-attention hidden stateë¥¼ concatenationí•œë‹¤.



## Experiments

### Quantitative Comparisons

<center><img src='{{"/assets/images/ë…¼ë¬¸ë¦¬ë·°/MagicAnimate-5.png" | relative_url}}' width="80%"></center>

### Qualitative Comparisons

<center><img src='{{"/assets/images/ë…¼ë¬¸ë¦¬ë·°/MagicAnimate-6.png" | relative_url}}' width="100%"></center>
