---
layout: single
title: "[ë…¼ë¬¸ë¦¬ë·°] MagicAnimate: Temporally Consistent Human Image Animation using Diffusion Model"
last_modified_at: 2025-06-14
categories: ["ë…¼ë¬¸ë¦¬ë·°"]
tags: ["Diffusion", "Video Generation"]
excerpt: "CVPR 2024"
use_math: true
toc: true
toc_sticky: true
---

**CVPR 2024** 
[[Paper]](https://arxiv.org/abs/2311.16498)
[[GitHub]](https://github.com/magic-research/magic-animate)

<details>
<summary><font color='#FF8C00'>ğŸ“ Summary</font></summary>
<div markdown="1">
<br>
ìƒˆë¡œìš´ appearance ì¸ì½”ë”ë¥¼ ì„¤ê³„í•˜ì—¬ reference ì´ë¯¸ì§€ì˜ ì •ì²´ì„±, ë°°ê²½ ë“±ì˜ ì •ë³´ë¥¼ ë³´ì¡´í•˜ì˜€ë‹¤.
- Appearance ì¸ì½”ë”ëŠ” base UNet êµ¬ì¡°ë¥¼ ë³µì œí•˜ì—¬ í•™ìŠµ
- UNetì˜ ì¤‘ê°„ featureë“¤ì„ base UNetì— ë‹¨ìˆœíˆ ë”í•˜ì§€ ì•Šê³ , attention blockì˜ keyì™€ valueì— í•©ì³ attention ì—°ì‚°ì„ ìˆ˜í–‰

Video frame fusion ê¸°ë²•ì„ í†µí•©í•˜ì—¬ ì• ë‹ˆë©”ì´ì…˜ ì˜ìƒ ì „ë°˜ì— ê±¸ì¹œ ìì—°ìŠ¤ëŸ¬ìš´ ì „í™˜ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ì˜€ë‹¤.
- ì—°ì‚°ëŸ‰ì˜ ë¬¸ì œ ë•Œë¬¸ì— ì „ì²´ í”„ë ˆì„ì„ ì—¬ëŸ¬ ê°œì˜ ì„¸ê·¸ë¨¼íŠ¸ë¡œ ë‚˜ëˆ„ì–´ í•™ìŠµí•˜ì˜€ìœ¼ë‚˜, ê° ì„¸ê·¸ë¨¼íŠ¸ë¼ë¦¬ ì¡°ê¸ˆì”© ê²¹ì¹˜ê²Œ í•¨

Image-video joint í•™ìŠµ ì „ëµì„ ì‚¬ìš©í•´ í”„ë ˆì„ë³„ í’ˆì§ˆì„ í–¥ìƒì‹œì¼°ë‹¤.
- ëœë¤ ë³€ìˆ˜ $r$ê³¼ ì„ê³„ê°’ì„ ì„¤ì •í•˜ì—¬, $r$ì˜ ê°’ì— ë”°ë¼ ë¹„ë””ì˜¤ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í• ê±´ì§€ ì´ë¯¸ì§€ ë°ì´í„°ì…‹ì„ ì‚¬ìš©í• ê±´ì§€ ì„¤ì •

</div>
</details>
<br>
<center><img src='{{"/assets/images/ë…¼ë¬¸ë¦¬ë·°/MagicAnimate-0.png" | relative_url}}' width="100%"></center>

## Introduction

ê¸°ì¡´ ì‚¬ëŒ ì´ë¯¸ì§€ ì• ë‹ˆë©”ì´ì…˜ì„ ìœ„í•œ ê¸°ë²•ë“¤ì€ í¬ê²Œ GAN ê¸°ë°˜ í”„ë ˆì„ì›Œí¬ì™€ Diffusion ê¸°ë°˜ í”„ë ˆì„ì›Œí¬ 2ê°€ì§€ë¡œ ë‚˜ëˆŒ ìˆ˜ ìˆë‹¤.

**ê¸°ì¡´ ì—°êµ¬ë“¤ì˜ í•œê³„ì **

- GAN ê¸°ë°˜ ê¸°ë²•

    ì€ ì œí•œëœ ëª¨ì…˜ ì „ì´ ëŠ¥ë ¥ì„ ê°€ì§€ë©°, ì´ë¡œ ì¸í•´ ê°€ë ¤ì§„ ì˜ì—­ì—ì„œ ë¹„í˜„ì‹¤ì ì¸ ë””í…Œì¼ì„ ìƒì„±í•˜ê³ , ì„œë¡œ ë‹¤ë¥¸ ì •ì²´ì„± ê°„(cross-identity)ì˜ ì¼ë°˜í™” ëŠ¥ë ¥ì´ ë¶€ì¡±í•˜ë‹¤.
- Diffusion ê¸°ë°˜ ê¸°ë²•

    ì‹œê°„ì  ì¼ê´€ì„±ì„ ê³ ë ¤í•˜ì§€ ì•Šì•„ ìƒì„±ëœ ë¹„ë””ì˜¤ì— flickering í˜„ìƒì´ ë‚˜íƒ€ë‚  ìˆ˜ ìˆë‹¤. ë˜í•œ, appearanceë¥¼ ì¸ì½”ë”©í•˜ê¸° ìœ„í•´ ì¼ë°˜ì ìœ¼ë¡œ CLIPì„ ì‚¬ìš©í•˜ëŠ” ë°, ì´ ë°©ë²•ì€ ë””í…Œì¼ ë³´ì¡´ì— ì·¨ì•½í•˜ë‹¤.

**ì œì•ˆí•˜ëŠ” ë°©ë²•**

MagicAnimateë¼ëŠ” ì‚¬ëŒ ì´ë¯¸ì§€ ì• ë‹ˆë©”ì´ì…˜ í”„ë ˆì„ì›Œí¬ ì œì•ˆí•œë‹¤.

- Temporal attention blockì„ ë„ì…í•´ ì‹œê°„ ì •ë³´ë¥¼ ì¸ì½”ë”©í•˜ì˜€ë‹¤.
- ê¸°ì¡´ì˜ CLIP ëŒ€ì‹ , ì •ì²´ì„±, ë°°ê²½, ì˜ìƒ ë“±ì˜ ìš”ì†Œë¥¼ ë” ì˜ ìœ ì§€í•  ìˆ˜ ìˆëŠ” ìƒˆë¡œìš´ appearance encoderë¥¼ ë„ì…í•˜ì˜€ë‹¤.
- ë‹¨ì¼ í”„ë ˆì„ ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ í™œìš©í•œ image-video joint í•™ìŠµ ì „ëµì„ ì„¤ê³„í•´ í”„ë ˆì„ë³„ í™”ì§ˆì„ í–¥ìƒì‹œì¼°ë‹¤.
- ë§¤ìš° ë‹¨ìˆœí•œ ë¹„ë””ì˜¤ ìœµí•© ê¸°ë²•ì„ í™œìš©í•´ ì¥ì‹œê°„ì˜ ì• ë‹ˆë©”ì´ì…˜ì—ì„œë„ ë¶€ë“œëŸ¬ìš´ ì „í™˜ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ì˜€ë‹¤.

## Methods

<center><img src='{{"/assets/images/ë…¼ë¬¸ë¦¬ë·°/MagicAnimate-1.png" | relative_url}}' width="100%"></center>

- Reference ì´ë¯¸ì§€ $I_{\text{ref}}$ë¥¼ appearance encoder $\mathcal{F}_a$ì— í†µê³¼ì‹œì¼œ appearance ì„ë² ë”© $\mathbf{y}_a$ë¡œ ë³€í™˜í•œë‹¤.
- ë§Œë“¤ê³ ì í•˜ëŠ” pose sequence $\mathbf{p}^{1:N}$ë¥¼ pose ControlNet $\mathcal{F}_p$ì— í†µê³¼ì‹œì¼œ motion condition $\mathbf{y}_p^{1:K}$ì„ ì¶”ì¶œí•œë‹¤.
- Video Diffusion Modelì€ ì´ ë‘ ì‹ í˜¸ë¥¼ ì¡°ê±´ìœ¼ë¡œ ë°›ì•„, reference ì´ë¯¸ì§€ê°€ ì£¼ì–´ì§„ motionì„ ë”°ë¼í•˜ëŠ” ë¹„ë””ì˜¤ë¥¼ ìƒì„±í•œë‹¤.

---

### 1. Temporal Consistency Modeling

2D UNet êµ¬ì¡°ë¥¼ 3D temporal UNet êµ¬ì¡°ë¡œ ë³€í˜•í•˜ëŠ” ê³¼ì •ìœ¼ë¡œ, [ê¸°ì¡´ ë°©ì‹](https://suniverse77.github.io/ë…¼ë¬¸ë¦¬ë·°/MAV/)ê³¼ ë™ì¼í•˜ë‹¤.

- ì›ë³¸ shape: $\mathbb{R}^{N\times C\times K\times H\times W}$
- ëª¨ë¸ ì…ë ¥ì„ ìœ„í•œ shape: $\mathbb{R}^{(NK)\times C\times H\times W}$
- temporal ëª¨ë“ˆ ì…ë ¥ì„ ìœ„í•œ shape: $\mathbb{R}^{(NHW)\times K\times C}$

### 2. Appearance Encoder

Reference ì´ë¯¸ì§€ì˜ ì–¼êµ´, ì‹ ì²´ íŠ¹ì§•, ë°°ê²½ ìš”ì†Œ ê°™ì€ ì„¸ë°€í•œ ì •ë³´ë¥¼ ë³´ì¡´í•˜ê¸° ìœ„í•´ ì„¤ê³„í•˜ì˜€ë‹¤.

êµ¬ì²´ì ìœ¼ë¡œ, Appearance EncoderëŠ” base UNet $\mathcal{F}_a(\theta^a)$ì˜ êµ¬ì¡°ë¥¼ ë³µì œí•˜ì—¬ ì‚¬ìš©í•˜ì˜€ë‹¤. (trainable copy)

$$
\mathbf{y}_a=\mathcal{F}_a(\mathbf{z}_t\mid I_{\text{ref}},\mathbf{t},\theta^a)
$$

ì¸ì½”ë”© ê³¼ì •ì€ ìœ„ì™€ ê°™ì´ í‘œí˜„ë˜ë©°, $\mathbf{y}_a$ëŠ” UNetì˜ middle blockê³¼ upsampling blockì—ì„œì˜ attention hidden stateë¥¼ ì˜ë¯¸í•œë‹¤.

ë‹¨ìˆœíˆ ì¡°ê±´ì„ residual ë°©ì‹ìœ¼ë¡œ ë”í•˜ëŠ” ControlNetê³¼ ë‹¬ë¦¬, ì¡°ê±´ featureë¥¼ UNetì˜ spatial self-attention layerì— ì£¼ì…í•œë‹¤.

$$
\text{Attention}(Q,K,V,\mathbf{y}_a)=\text{Softmax}(\frac{QK'^\top}{\sqrt{d}})V'
$$

$$
Q=W^Q\mathbf{z}_t,~K'=W^K[\mathbf{z}_t,\mathbf{y}_a],~V'=W^V[\mathbf{z}_t,\mathbf{y}_a]
$$

Keyì™€ Valueë¥¼ ìƒì„±í•  ë•Œ, $\mathbf{y}_a$ì™€ ì›ë˜ UNetì˜ self-attention hidden stateë¥¼ concatenationí•œë‹¤.

### 3. Animation Pipeline

#### Motion transfer

ControlNetì€ OpenPose keypointsë¥¼ ì´ìš©í•´ reference ì‚¬ëŒ ì´ë¯¸ì§€ë¥¼ ì• ë‹ˆë©”ì´ì…˜í™”í•˜ëŠ” ë° ì¼ë°˜ì ìœ¼ë¡œ ì‚¬ìš©ëœë‹¤.

ì´ ë°©ì‹ì€ ê·¸ëŸ´ë“¯í•œ ê²°ê³¼ë¥¼ ìƒì„±í•˜ì§€ë§Œ, ì €ìë“¤ì€ ì‹ ì²´ì˜ ì£¼ìš” keypointë“¤ì´ ë“œë¬¼ê³  íšŒì „ê³¼ ê°™ì€ íŠ¹ì • ì›€ì§ì„ì— ëŒ€í•´ ê²¬ê³ í•˜ì§€ ì•Šë‹¤ê³  ì£¼ì¥í•œ.

ë”°ë¼ì„œ ë³´ë‹¤ ë°€ë„ ë†’ê³  ê²¬ê³ í•œ í¬ì¦ˆ ì¡°ê±´ì„ ìœ„í•´ DensePoseë¥¼ ëª¨ì…˜ ì‹ í˜¸ $\mathbf{p}_i$ë¡œ ì„ íƒí•˜ì˜€ë‹¤.

í¬ì¦ˆ ControlNet $\mathbf{y}_{\mathbf{p},i}=\mathcal{F}_(\cdot,\theta^{\mathbf{p}})$ë¥¼ ì‚¬ìš©í•˜ë©°, í”„ë ˆì„ $i$ì— ëŒ€í•œ pose conditionì€ ì•„ë˜ì™€ ê°™ì´ ê³„ì‚°ëœë‹¤.

$$
\mathcal{F}_{\mathbf{p}}(\mathbf{z}_t\mid\mathbf{p},\mathbf{t},\theta^{\mathbf{p}})
$$

#### Denoising process

ë…¸ì´ì¦ˆ ì˜ˆì¸¡ í•¨ìˆ˜ $\epsilon_\theta^{1:K}(\cdot)$ì€ ì•„ë˜ì™€ ê°™ì´ ì •ì˜ëœë‹¤.

$$
\epsilon_\theta^{1:K}(\mathbf{z}_t^{1:K},\mathbf{t},I_{\text{ref}},\mathbf{p}^{1:K})
=
\mathcal{F}^T(\mathbf{z}_t^{1:K}\mid \mathbf{t},\mathbf{y}_a,\mathbf{y}_p^{1:K})
$$

#### Long video animation

ì¥ì‹œê°„ ë¹„ë””ì˜¤ë¥¼ ìƒì„±í•˜ë ¤ë©´ ì—°ì‚°ëŸ‰ì´ ë§ì´ í•„ìš”í•˜ê¸° ë•Œë¬¸ì—, segment-by-segment ë°©ì‹ìœ¼ë¡œ ìƒì„±í•˜ì˜€ë‹¤. (ì—¬ëŸ¬ ê°œì˜ í”„ë ˆì„ìœ¼ë¡œ ë¶„í• í•´ì„œ ìƒì„±)

í•˜ì§€ë§Œ ê¸´ ë™ì˜ìƒì„ í”„ë ˆì„ ë‹¨ìœ„ë¡œ ë‚˜ëˆ ì„œ ìƒì„±í•˜ë©´ ì„¸ê·¸ë¨¼íŠ¸ ì‚¬ì´ì˜ ì „í™˜ì´ ë¶€ìì—°ìŠ¤ëŸ½ê³  ë””í…Œì¼ì´ ì¼ê´€ë˜ì§€ ì•Šì„ ìˆ˜ ìˆê¸° ë•Œë¬¸ì— inference ë‹¨ê³„ì—ì„œ sliding window ê¸°ë²•ì„ ì ìš©í•˜ì˜€ë‹¤.

- ê¸´ ëª¨ì…˜ ì‹œí€€ìŠ¤(ì´ $N$ í”„ë ˆì„)ë¥¼ $K$ì˜ ê¸¸ì´ë¥¼ ê°–ëŠ” ì—¬ëŸ¬ ê°œì˜ ì„¸ê·¸ë¨¼íŠ¸ë¡œ ë‚˜ëˆˆë‹¤.
- ì„¸ê·¸ë¨¼íŠ¸ë“¤ì€ ì„œë¡œ $s$ í”„ë ˆì„ë§Œí¼ ê²¹ì¹˜ë„ë¡(ì˜¤ë²„ë©) ì„¤ì •

$$
\lbrace
\mathbf{z}^{1:K},\mathbf{z}^{K-s+1:2K-s},\dots,\mathbf{z}^{n(K-s)+1:n(K-s)+K}
\rbrace
~~,~~
n=\left\lceil\frac{N-K}{K-s}\right\rceil
$$

ë§ˆì§€ë§‰ segmentì˜ ê¸¸ì´ëŠ” $K$ë³´ë‹¤ ì‘ì„ ìˆ˜ ìˆìœ¼ë©°, ì´ë•ŒëŠ” ë‹¨ìˆœí•˜ê²Œ ì²˜ìŒ ëª‡ ì¥ì˜ í”„ë ˆì„ìœ¼ë¡œ ê¸¸ì´ê°€ $K$ê°€ ë˜ë„ë¡ íŒ¨ë”©í•˜ì˜€ë‹¤.

ê²½í—˜ì ìœ¼ë¡œ, ê° segment ë‚´ì—ì„œì˜ ì´ˆê¸° ë…¸ì´ì¦ˆëŠ” ë™ì¼í•˜ê²Œ ì´ˆê¸°í™”í•˜ëŠ” ê²ƒì´ ì„±ëŠ¥ì´ ì¢‹ì•˜ë‹¤ê³  í•œë‹¤.

ê° ì„¸ê·¸ë¨¼íŠ¸ë§ˆë‹¤ ë…¸ì´ì¦ˆ ì˜ˆì¸¡ ëª¨ë¸ $\epsilon_\theta^{1:K}$ì„ ì–»ê³ , ê²¹ì¹˜ëŠ” ë¶€ë¶„ì€ í‰ê· ì„ ë‚´ì„œ $\epsilon_\theta^{1:N}$ìœ¼ë¡œ ë³‘í•©í•˜ì˜€ë‹¤.

### 4. Training

#### Learning objectives

ì²« ë²ˆì§¸ stageì—ì„œëŠ” temporal attention layerë¥¼ ì œì™¸í•˜ê³ , appearance encoderì™€ pose ControlNetì„ í•¨ê»˜ í•™ìŠµí•œë‹¤.

$$
\mathcal{L}_1 =
\mathbb{E}_{\mathbf{z}_0,\, t,\, I_{\mathrm{ref}},\, \mathbf{p}_i,\, \boldsymbol{\epsilon} \sim \mathcal{N}(0,1)}
\left[
\left\| \boldsymbol{\epsilon} - \boldsymbol{\epsilon}_\theta \right\|_2^2
\right]
$$

ë‘ ë²ˆì§¸ stageì—ì„œëŠ” temporal attention layerë§Œ í•™ìŠµí•œë‹¤.

$$
\mathcal{L}_2 =
\mathbb{E}_{\mathbf{z}_0^{1:K},\, t,\, I_{\mathrm{ref}},\, \mathbf{p}^{1:K},\, \boldsymbol{\epsilon}^{1:K} \sim \mathcal{N}(0,1)}
\left[
\left\| \boldsymbol{\epsilon}^{1:K} - \boldsymbol{\epsilon}_\theta^{1:K} \right\|_2^2
\right]
$$

#### Image-video joint training

**ì²« ë²ˆì§¸ stage**

- ì„ê³„ê°’ $\tau_0$ë¥¼ ì„¤ì •í•˜ê³  ëœë¤í•œ ìˆ«ì $r\sim U(0,1)$ì„ ë½‘ëŠ”ë‹¤.
- $r\leq\tau_0$ì´ë©´, ì´ë¯¸ì§€ì™€ í•´ë‹¹ ì´ë¯¸ì§€ì—ì„œ ì¶”ì •ëœ í¬ì¦ˆë¥¼ ì¡°ê±´ìœ¼ë¡œ ì‚¬ìš©í•˜ê³ , ëª¨ë¸ì€ í•´ë‹¹ ì´ë¯¸ì§€ë¥¼ ì¬êµ¬ì„±í•˜ë„ë¡ í•™ìŠµí•œë‹¤.

**ë‘ ë²ˆì§¸ stage**

ì‹œê°„ì  ì¼ê´€ì„±ë„ í–¥ìƒì‹œí‚¤ëŠ” ë™ì‹œì— ê°œë³„ í”„ë ˆì„ë³„ í’ˆì§ˆë„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ ì„ê³„ê°’ì— ë”°ë¼ ë‹¤ë¥¸ ì¡°ê±´ì—ì„œ í•™ìŠµëœë‹¤.

- $r\leq\tau_1$ì´ë©´, ì´ë¯¸ì§€ ë°ì´í„°ì…‹ì„ ì´ìš©í•´ í•™ìŠµí•œë‹¤.
- ê·¸ ì™¸ëŠ” ë¹„ë””ì˜¤ ë°ì´í„°ì…‹ì„ ì´ìš©í•´ í•™ìŠµí•œë‹¤.

$$
\boldsymbol{\epsilon}_\theta^{1:K} =
\begin{cases}
\boldsymbol{\epsilon}_\theta^{1:K}\left( \mathbf{z}_t,\, t,\, I_{\mathrm{ref}},\, \mathbf{p}_i \right), & \text{with } i = \mathrm{ref}, \quad \text{if } r \leq \tau_1, \\
\boldsymbol{\epsilon}_\theta^{1:K}\left( \mathbf{z}_t,\, t,\, I_{\mathrm{ref}},\, \mathbf{p}_i \right), & \text{with } i \neq \mathrm{ref}, \quad \text{if } \tau_1 \leq r \leq \tau_2, \\
\boldsymbol{\epsilon}_\theta^{1:K}\left( \mathbf{z}_t^{1:K},\, t,\, I_{\mathrm{ref}},\, \mathbf{p}^{1:K} \right), & \text{if } r \geq \tau_2.
\end{cases}
$$

## Experiments

### Quantitative Comparisons

<center><img src='{{"/assets/images/ë…¼ë¬¸ë¦¬ë·°/MagicAnimate-2.png" | relative_url}}' width="80%"></center>

### Qualitative Comparisons

<center><img src='{{"/assets/images/ë…¼ë¬¸ë¦¬ë·°/MagicAnimate-3.png" | relative_url}}' width="100%"></center>
