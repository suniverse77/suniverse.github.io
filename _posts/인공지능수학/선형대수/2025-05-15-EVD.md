---
layout: single
title: "[선형대수] Eigen Value Decomposition (EVD)"
last_modified_at: 2025-05-15
categories: ["인공지능 수학"]
tags: ["선형대수"]
excerpt: "고유값 분해"
use_math: true
toc: true
toc_sticky: true
---

## Diagonal Matrix

![Figure 1](/assets/images/인공지능수학/3-3. Figure1.png){: style="display:block; margin:0 auto; width: 30%; height: 30%;"}

$$
D=\begin{bmatrix}d_1&\cdots$0\\\vdots&\ddot\vdots\\0&\cdots&d_n\end{bmatrix}
$$


Diagnoal Matrix는 유용한 성질들을 가지고 있다.

1. 대각 행렬의 power는 각 대각성분을 $k$승 하면 됨

   ![Figure 2](/assets/images/인공지능수학/3-3. Figure2.png){: style="display:block; margin:0 auto; width: 35%; height: 35%;"}
2. 대각 행렬의 inverse는 각 대각 성분에 역수를 취하면 됨

   ![Figure 3](/assets/images/인공지능수학/3-3. Figure3.png){: style="display:block; margin:0 auto; width: 35%; height: 35%;"}
3. Determinant는 대각 성분들의 곱과 같음

   $$
   \text{det}(D)=d_1d_2\cdots d_n
   $$

## EVD

$$
A=V\Lambda V^{-1}
$$

Square Matrix $A$를 eigenvalue와 eigenvector를 이용해 분해 하는 방법을 EVD라고 한다.

- $V$: 고유벡터들을 열로 갖는 행렬
- $\Lambda$: 대각 성분이 고유값인 대각행렬

EVD가 가능한 행렬을 diagonalizable(대각화 가능)하다고 한다.

EVD를 사용하면 아래의 연산들이 쉬워진다.
1. $A^k=V\Lambda^kV^{-1}$
2. $A^{-1}=V\Lambda^{-1}V^{-1}$
3. $\text{det}(A)=\prod_{i=1}^n\lambda_i$
4. $\text{tr}(A)=\sum_{i=1}^n\lambda_i$

### EVD의 조건
1. $A$가 반드시 square matrix이어야 한다.
2. $A$의 고유벡터들이 선형 독립이어야 한다. (Algebraic Multiplicity = Gemoetric Multiplicity인 경우)

   - Algebraic Multiplicity: 특성 방정식에서 고유값의 중복 횟수
   - Gemoetric Multiplicity: 고유값에 대응하는 고유벡터들의 개수 (null space의 차원)
3. $A$가 symmetric matrix인 경우 항상 EVD가 가능하며, 이 경우 orthogonal matrix로 분해가 가능하다.

   $A=Q\Lambda Q^\top$ , $QQ^\top=I$

> ex)
>
> $$
> A=\begin{bmatrix}2&1\\0&2\end{bmatrix}
> $$
>
> ---
> $\lambda_1=\lambda_2=2$이므로, 2개의 중복 고유값을 가진다.
>
> 그러나 해당 고유값에 대응하는 고유벡터는 1개이므로, $A$는 EVD가 불가능하다.
