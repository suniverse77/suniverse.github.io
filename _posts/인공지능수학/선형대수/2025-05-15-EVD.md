---
layout: single
title: "[선형대수] Eigen Value Decomposition (EVD)"
last_modified_at: 2025-05-15
categories: ["인공지능 수학"]
tags: ["선형대수"]
excerpt: "고유값 분해"
use_math: true
toc: true
toc_sticky: true
---

## Diagonal Matrix

![Figure 1](/assets/images/인공지능수학/3-3. Figure1.png){: style="display:block; margin:0 auto; width: 30%; height: 30%;"}

Diagnoal Matrix는 유용한 성질들을 가지고 있다.

1. 대각 행렬의 power는 각 대각성분을 $k$승 하면 됨

   ![Figure 2](/assets/images/인공지능수학/3-3. Figure2.png){: style="display:block; margin:0 auto; width: 35%; height: 35%;"}
2. 대각 행렬의 inverse는 각 대각 성분에 역수를 취하면 됨

   ![Figure 3](/assets/images/인공지능수학/3-3. Figure3.png){: style="display:block; margin:0 auto; width: 35%; height: 35%;"}
3. Determinant는 대각 성분들의 곱과 같음

   $$
   \text{det}(D)=d_1d_2\cdots d_n
   $$

## EVD

$$
A=V\Lambda V^{-1}
$$

Square Matrix $A$를 eigenvalue와 eigenvector를 이용해 분해 하는 방법을 EVD라고 한다.

- $V$: 고유벡터들을 열로 갖는 행렬
- $\Lambda$: 고유값들이 대각선에 있는 대각행렬

**EVD**
1. $A$가 반드시 square matrix이어야 함
2. $A$의 고유벡터들이 선형 독립이어야 함
3. $A$가 symmetric matrix인 경우 항상 EVD가 가능하며, 이 경우 아래의 식이 성립함

   $A=Q\Lambda Q^\top$

EVD를 사용하면 아래의 연산들이 쉬워진다.
1. $A^k=V\Lambda^kV^{-1}$
2. $A^{-1}=V\Lambda^{-1}V^{-1}$
3. $\text{det}(A)=\prod_{i=1}^n\lambda_i$
4. $\text{tr}(A)=\sum_{i=1}^n\lambda_i$
